{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SailBoatEnvironment:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.35):\n",
    "        self.step_num=0\n",
    "        #self.wind_direction = np.random.uniform(0, 2*np.pi)\n",
    "        #self.boat_position = np.array([222, 222])\n",
    "        #self.target_position = np.array([np.random.uniform(-10, 10), np.random.uniform(-10, 10)])\n",
    "        self.sail_configs = np.linspace(0, 1, 16) #16 allowed positions of the sail\n",
    "        self.rudder_configs = np.linspace(-np.pi/4, np.pi/4, 16) #The values of -np.pi/4 and np.pi/4 are chosen to represent the limits of the rudder configuration. These values correspond to the maximum angles \n",
    "                                                                #that the rudder can be turned left and right from the center position.The choice of np.pi/4 as the maximum #\n",
    "                                                                # angle is somewhat arbitrary, but it is a common choice in sailing and boating applications.\n",
    "        \n",
    "        \n",
    "        #self.q_table = np.zeros((16, 16, 3))\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def reset(self):\n",
    "        self.wind_direction = np.pi/2# np.random.uniform(0, 2*np.pi)\n",
    "        self.boat_position = np.array([0, 0]) #fixed starting point\n",
    "        self.target_position = np.array([55,100]) #fixed target position\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        relative_wind_direction = self.wind_direction - np.arctan2(*self.boat_position[::-1])\n",
    "        distance_to_target = np.linalg.norm(self.boat_position - self.target_position)\n",
    "        return relative_wind_direction, distance_to_target\n",
    "\n",
    "    def step(self, action):\n",
    "        sail_config, rudder_config = action\n",
    "        sail_force = sail_config * np.sin(self.wind_direction - np.arctan2(*self.boat_position[::-1]))\n",
    "        rudder_force = rudder_config * np.cos(self.wind_direction - np.arctan2(*self.boat_position[::-1]))\n",
    "        boat_velocity = np.array([np.cos(self.wind_direction), np.sin(self.wind_direction)]) * sail_force + np.array([-np.sin(self.wind_direction), np.cos(self.wind_direction)]) * rudder_force\n",
    "        self.boat_position = self.boat_position + boat_velocity#.astype(np.float64)\n",
    "        state = self.get_state()\n",
    "        self.step_num+=1\n",
    "        done = False\n",
    "        reward = -1\n",
    "\n",
    "        if np.any(np.abs(self.boat_position) > 20):\n",
    "            done = True\n",
    "            reward = -10\n",
    "\n",
    "        distance_to_target = state[1]\n",
    "        if distance_to_target < 0.5:\n",
    "            done = True\n",
    "            reward = 150\n",
    "\n",
    "#         # Q-learning update\n",
    "#         sail_idx = np.argmin(np.abs(self.sail_configs - sail_config))\n",
    "#         rudder_idx = np.argmin(np.abs(self.rudder_configs - rudder_config))\n",
    "#         q_current = self.q_table[sail_idx, rudder_idx, 0]\n",
    "#         q_next = np.max(self.q_table[sail_idx, rudder_idx, :])\n",
    "#         self.q_table[sail_idx, rudder_idx, 0] += self.alpha * (reward + self.gamma * q_next - q_current)\n",
    "\n",
    "        return boat_velocity, self.boat_position, state, reward, done, self.step_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3., 24.,  5.,  6.,  7.,  8.,  9., 11., 12., 13.],\n",
       "       [ 7., 15., 44., 45., 56., 77., 80.,  8., -7., 99.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table=np.zeros((4,10))\n",
    "\n",
    "q_table[0,1]=24 #distance to target\n",
    "q_table[0,0]=3 #wind direction\n",
    "q_table[1,1]=15 #distance to target\n",
    "q_table[1,0]=7 #wind direction\n",
    "q_table[0,2:10]=5,6,7,8,9,11,12,13\n",
    "q_table[1,2:10]=44,45,56,77,80,8,-7,99\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -43,   -3,  -42,  -74,  -57,  -77,  -41,  -48],\n",
       "        [ -64,  -23,  -87,  -34,  -67,   -3,  -54,  -45],\n",
       "        [ -69,  -20,  -83,  -83,  -45,  -57,  -98,  -98],\n",
       "        [ -35,  -51,  -57,  -68,  -71,  -15,  -71,  -45],\n",
       "        [  -5,  -88,  -50,  -55,  -32,  -14,  -83,  -84],\n",
       "        [ -96,  -34,  -65,  -94,  -95,  -21,  -66,  -51],\n",
       "        [ -22,  -66,  -91,  -66,  -55,  -45,  -10,  -57]],\n",
       "\n",
       "       [[ -27,   -1,  -33,  -91,  -15,  -11, -100,   -3],\n",
       "        [ -52,  -10,  -11,   -7,  -13,  -71,  -67,   -7],\n",
       "        [ -56,  -65,  -86,  -36,   -9,  -46,  -48,  -49],\n",
       "        [ -34,  -66,  -87,   -1,  -53,  -89,  -25,  -10],\n",
       "        [ -22,   -8,  -14,  -67,  -89,  -95,  -70,  -76],\n",
       "        [ -41,  -66,  -86,  -84,  -90,  -61,  -55,  -86],\n",
       "        [ -44,  -55,  -43,  -56,  -63,  -67,  -85,  -88]],\n",
       "\n",
       "       [[ -85,   -3,  -49,  -44,  -75,  -69,  -56,  -81],\n",
       "        [ -15,  -28,  -93,  -46,  -23,  -12,  -52,  -56],\n",
       "        [ -22,  -85,  -66,  -80,  -43,  -19,  -62,   -8],\n",
       "        [ -55,  -70,  -83,  -32,  -49,  -16,  -71,  -77],\n",
       "        [ -25,  -24,  -81,  -27,  -28,  -30,  -13,   -2],\n",
       "        [ -18,  -95,   -6,  -81,  -17,   -1,  -64,  -87],\n",
       "        [ -65,  -43,  -81,  -98,  -65,  -16,  -64,  -17]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.random.randint(low=-100, high=0, size=(3,7,2+3+3))\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 24 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_state\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m np\u001b[38;5;241m.\u001b[39mmax(\u001b[43mq_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 24 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "new_state=(3,24)\n",
    "np.max(q_table[new_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 16\u001b[0m\n\u001b[0;32m      9\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Choose action using epsilon-greedy policy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#if np.random.uniform() < env.epsilon:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m#action = [np.random.choice(env.sail_configs), np.random.choice(env.rudder_configs)]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     sail_idx, rudder_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(env\u001b[38;5;241m.\u001b[39msail_configs, \u001b[43maction\u001b[49m[\u001b[38;5;241m0\u001b[39m]), np\u001b[38;5;241m.\u001b[39msearchsorted(env\u001b[38;5;241m.\u001b[39mrudder_configs, action[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     17\u001b[0m     action \u001b[38;5;241m=\u001b[39m [env\u001b[38;5;241m.\u001b[39msail_configs[sail_idx], env\u001b[38;5;241m.\u001b[39mrudder_configs[rudder_idx]]\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Take action\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'action' is not defined"
     ]
    }
   ],
   "source": [
    "env=SailBoatEnvironment()\n",
    "q_table = np.zeros((16, 16, 3))\n",
    "\n",
    "num_episodes = 1\n",
    "#num_steps = 1000\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        # Choose action using epsilon-greedy policy\n",
    "        \n",
    "        #if np.random.uniform() < env.epsilon:\n",
    "            #action = [np.random.choice(env.sail_configs), np.random.choice(env.rudder_configs)]\n",
    "        #else:\n",
    "        sail_idx, rudder_idx = np.searchsorted(env.sail_configs, action[0]), np.searchsorted(env.rudder_configs, action[1])\n",
    "        action = [env.sail_configs[sail_idx], env.rudder_configs[rudder_idx]]\n",
    "        \n",
    "        # Take action\n",
    "        boat_v, boat_pos, next_state, reward, done, step_number = env.step(action)\n",
    "        \n",
    "        # Update Q-table\n",
    "        sail_idx, rudder_idx = np.searchsorted(env.sail_configs, action[0]), np.searchsorted(env.rudder_configs, action[1])\n",
    "        q_current = q_table[sail_idx, rudder_idx, 0]\n",
    "        q_next = np.max(q_table[sail_idx, rudder_idx, :])\n",
    "        q_table[sail_idx, rudder_idx, 0] += env.alpha * (reward + env.gamma * q_next - q_current)\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        #print(f\"Step: {step_number}, BoatV:{np.round(boat_v,2)} , Boat Pos:{np.round(boat_pos,2)}\")\n",
    "    #print(f\"Episode {episode+1}, BoatV:{boat_v} , Boat Pos:{boat_pos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_searchsorted_dispatcher() missing 1 required positional argument: 'v'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msail_configs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _searchsorted_dispatcher() missing 1 required positional argument: 'v'"
     ]
    }
   ],
   "source": [
    "np.searchsorted(env.sail_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.sail_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(env.sail_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.searchsorted(env.sail_configs, action[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table[1,4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env = SailBoatEnvironment()\n",
    "num_episodes = 3000\n",
    "num_steps =1000\n",
    "\n",
    "# create empty arrays to store positions for each episode\n",
    "boat_positions = np.zeros((num_episodes, 2)) \n",
    "target_positions = np.tile(np.array([55,100]), (num_episodes, 1))\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        # Choose action using epsilon-greedy policy\n",
    "        if np.random.uniform() < env.epsilon:\n",
    "            action = [np.random.choice(env.sail_configs), np.random.choice(env.rudder_configs)]\n",
    "        else:\n",
    "            sail_idx, rudder_idx = np.searchsorted(env.sail_configs, action[0]), np.searchsorted(env.rudder_configs, action[1])\n",
    "            action = [env.sail_configs[sail_idx], env.rudder_configs[rudder_idx]]\n",
    "\n",
    "        # Take action\n",
    "        boat_v, boat_pos, next_state, reward, done = env.step(action)\n",
    "        \n",
    "\n",
    "        # Update Q-table\n",
    "        sail_idx, rudder_idx = np.searchsorted(env.sail_configs, action[0]), np.searchsorted(env.rudder_configs, action[1])\n",
    "        q_current = q_table[sail_idx, rudder_idx, 0]\n",
    "        q_next = np.max(q_table[sail_idx, rudder_idx, :])\n",
    "        q_table[sail_idx, rudder_idx, 0] += env.alpha * (reward + env.gamma * q_next - q_current)\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    \n",
    "    # store final position in boat_positions array\n",
    "    boat_positions[episode, :] = state\n",
    "    \n",
    "    print(f\"Episode {episode+1}, Total reward: {total_reward}, New Position: ({state[0]:.2f}, {state[1]:.2f}), Target Position: ({env.target_position[0]:.2f}, {env.target_position[1]:.2f})\")\n",
    "\n",
    "# create scatter plot of boat positions and target positions\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(target_positions[:, 0], target_positions[:, 1], color='red',label='Target Position')\n",
    "ax.scatter(boat_positions[:, 0], boat_positions[:, 1], color='gray', label='Boat Position')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Q-table is a 3-dimensional numpy array with dimensions (11, 11, 3). The first two dimensions correspond to the sail and rudder configurations, respectively, and the third dimension corresponds to the Q-values for each possible action (there are 3 actions in total: sail left, sail straight, and sail right)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self.wind_direction is a random value between 0 and 2π.\n",
    "self.boat_position is a NumPy array containing the initial position of the boat, which is (0, 0).\n",
    "self.target_position is a NumPy array containing the position of the target, which is a random point within a rectangle centered at the origin with width and height of 20 units.\n",
    "self.sail_configs is a NumPy array containing 11 equally spaced values between 0 and 1, representing the possible sail configurations.\n",
    "self.rudder_configs is a NumPy array containing 11 equally spaced values between -π/4 and π/4, representing the possible rudder configurations.\n",
    "self.q_table is a 3-dimensional NumPy array of zeros with shape (11, 11, 3), representing the Q-values for each possible combination of sail and rudder configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sail_idx = np.argmin(np.abs(self.sail_configs - sail_config)) finds the index of the sail configuration that is closest to the desired sail configuration specified by sail_config. This is used to index into the first dimension of the Q-table.\n",
    "\n",
    "rudder_idx = np.argmin(np.abs(self.rudder_configs - rudder_config)) finds the index of the rudder configuration that is closest to the desired rudder configuration specified by rudder_config. This is used to index into the second dimension of the Q-table.\n",
    "\n",
    "q_current = self.q_table[sail_idx, rudder_idx, 0] retrieves the current Q-value for the current state and action (which is the \"sail straight\" action, corresponding to the index 0 in the third dimension).\n",
    "\n",
    "q_next = np.max(self.q_table[sail_idx, rudder_idx, :]) computes the estimated Q-value for the next state, which is the maximum Q-value over all possible actions in the next state (i.e., the action that maximizes the Q-value). This is used to estimate the expected total reward that can be obtained from the next state.\n",
    "\n",
    "self.q_table[sail_idx, rudder_idx, 0] += self.alpha * (reward + self.gamma * q_next - q_current) updates the Q-value for the current state and action, using the Q-learning update rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Q-learning update equation is used to update the Q-value for the current state and action. The Q-value for the current state and action is q_current, and q_next is the maximum Q-value for the next state. The update is performed as follows:\n",
    "\n",
    "new_q_value = old_q_value + learning_rate * (reward + discount_factor * max_q_next - old_q_value)\n",
    "\n",
    "where learning_rate is the step size, reward is the reward obtained from the current action, discount_factor is the discount factor for future rewards, and max_q_next is the maximum Q-value for the next state.\n",
    "\n",
    "In the code, q_current is the current Q-value for the current state and action, and q_next is the maximum Q-value for the next state. The Q-value for the current state and action is updated using the above equation, and the new value is stored back in the Q-table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relative_wind_direction = self.wind_direction - np.arctan2(*self.boat_position[::-1])\n",
    "self.wind_direction: This is a scalar value that represents the direction of the wind, expressed in radians.\n",
    "np.arctan2(*self.boat_position[::-1]): This is a function call to np.arctan2, which computes the arctangent of the ratio of two given inputs. In this case, the inputs are the components of the boat's position vector, reversed using [::-1]. The * before self.boat_position[::-1] unpacks the tuple of components into separate arguments for the np.arctan2 function. The resulting output is the angle in radians between the positive x-axis and a line connecting the boat's position to the origin.\n",
    "self.wind_direction - np.arctan2(*self.boat_position[::-1]): This subtracts the angle from step 2 from the wind direction angle from step 1, resulting in the relative wind direction, which is the angle in radians between the boat's heading and the direction of the wind.\n",
    "Overall, this line of code is computing the relative wind direction, which is an important parameter for calculating the sail force applied to the boat in the subsequent lines of code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
